<!DOCTYPE html><html lang="en" class="__variable_0dcb31 __variable_d47d9e __variable_69257b __variable_ccf310 __variable_b278cd"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="https://illuminaite.github.io/_next/static/media/111c93f1bc244164-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://illuminaite.github.io/_next/static/media/828e2958d60bafae-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://illuminaite.github.io/_next/static/media/acaa31bcd8de99a2-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://illuminaite.github.io/_next/static/media/b7ae23d8a9c319da-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://illuminaite.github.io/_next/static/media/c8802c19af58d4c3-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://illuminaite.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://illuminaite.github.io/_next/static/media/f18367e159541896-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/images/blogs/intro-to-ai-ethics.png"/><link rel="preload" as="image" href="/images/blogs/letter-from-illuminai.png"/><link rel="stylesheet" href="https://illuminaite.github.io/_next/static/css/855e81ff297effac.css" data-precedence="next"/><link rel="stylesheet" href="https://illuminaite.github.io/_next/static/css/ce2246e58b109e16.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="https://illuminaite.github.io/_next/static/chunks/webpack-b3042b0fdd2346c1.js"/><script src="https://illuminaite.github.io/_next/static/chunks/4bd1b696-3f85a3656a7f05a4.js" async=""></script><script src="https://illuminaite.github.io/_next/static/chunks/215-16fcddfd98afb488.js" async=""></script><script src="https://illuminaite.github.io/_next/static/chunks/main-app-b6335d33a5a176d8.js" async=""></script><script src="https://illuminaite.github.io/_next/static/chunks/231-6b28840e4f5e2501.js" async=""></script><script src="https://illuminaite.github.io/_next/static/chunks/app/blogs/%5Bslug%5D/page-465cbca8ec132ab4.js" async=""></script><meta name="next-size-adjust"/><title>illuminaite academy</title><meta name="description" content="Demystifying the world of CS &amp; AI. Building a network of interdisciplinary students &amp; opportunities."/><meta name="author" content="illuminaite academy"/><meta name="keywords" content="AI,computer science,education,technology,interdisciplinary,workshops,community"/><meta name="creator" content="illuminaite academy"/><meta name="publisher" content="illuminaite academy"/><meta property="og:title" content="illuminaite academy"/><meta property="og:description" content="Demystifying the world of CS &amp; AI. Building a network of interdisciplinary students &amp; opportunities."/><meta property="og:url" content="https://illuminaite.github.io/"/><meta property="og:site_name" content="illuminaite academy"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="illuminaite academy"/><meta name="twitter:description" content="Demystifying the world of CS &amp; AI. Building a network of interdisciplinary students &amp; opportunities."/><link rel="shortcut icon" href="/images/illuminaite_logo.ico"/><link rel="icon" href="/images/illuminaite_logo.ico"/><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.14.0/css/all.css" integrity="sha384-HzLeBuhoNPvSl5KYnjx0BT+WB0QEEqLprO+NBkkk5gbc67FTaL7XIGa2w1L0Xbgc" crossorigin="anonymous"/><script src="https://illuminaite.github.io/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_0dcb31 font-karla antialiased bg-black min-h-screen flex justify-center px-[1px] py-[1px]"><main class="w-full max-w-[1400px] bg-white min-h-fit shadow-[0_0_0_1px_#000]"><nav class="bg-black h-20 flex justify-center items-center text-lg sticky top-0 z-50"><div class="flex justify-between items-center h-20 w-full max-w-7xl mx-auto px-12"><a class="text-white text-xl font-italiana cursor-pointer tracking-wider hover:text-primary-coral transition-colors duration-300" href="/">illuminAI</a><div class="flex lg:hidden"><button class="flex flex-col justify-around w-6 h-6 cursor-pointer transition-all duration-300 "><span class="block w-6 h-0.5 bg-white transition-all duration-300 "></span><span class="block w-6 h-0.5 bg-white transition-all duration-300 "></span><span class="block w-6 h-0.5 bg-white transition-all duration-300 "></span></button></div><ul class="hidden lg:flex items-center list-none uppercase tracking-wider"><li class="h-20"><a class="font-italiana text-primary-light flex items-center justify-center w-32 h-full transition-all duration-300 hover:text-primary-coral" href="/about/">ABOUT</a></li><li class="h-20"><a class="font-italiana text-primary-light flex items-center justify-center w-32 h-full transition-all duration-300 hover:text-primary-coral" href="/team/">TEAM</a></li><li class="h-20"><a class="font-italiana text-primary-light flex items-center justify-center w-32 h-full hover:text-primary-coral transition-all duration-300" href="/blogs/">BLOGS</a></li><li class="flex justify-center items-center px-4 h-20"><a href="mailto:illuminaiteacademy@gmail.com" class="font-italiana flex justify-center items-center py-2.5 px-5 rounded bg-[#8B0000] text-white hover:bg-[#6F0000] transition-all duration-300 uppercase tracking-wider">CONTACTS</a></li></ul><ul class="lg:hidden fixed top-20 left-0 w-full h-screen bg-black flex flex-col items-center pt-8 uppercase tracking-wider transition-all duration-300 opacity-0 invisible"><li class="my-4"><a class="font-italiana text-primary-light text-xl hover:text-primary-coral transition-all duration-300" href="/about/">ABOUT</a></li><li class="my-4"><a class="font-italiana text-primary-light text-xl hover:text-primary-coral transition-all duration-300" href="/team/">TEAM</a></li><li class="my-4"><a class="font-italiana text-primary-light text-xl hover:text-primary-coral transition-all duration-300" href="/blogs/">BLOGS</a></li><li class="my-4"><a href="mailto:illuminaiteacademy@gmail.com" class="font-italiana bg-[#8B0000] text-white py-2.5 px-5 rounded hover:bg-[#6F0000] transition-all duration-300">CONTACTS</a></li></ul></div></nav><div class="relative z-10 pt-8 bg-white mx-8 overflow-hidden"><div class="flex justify-between items-baseline w-full"><div class="flex items-baseline md:gap-2"><h1 class="text-5xl md:text-6xl font-italiana font-light tracking-tight px-4"><span class="text-[#BF2929]">illumin</span><span class="text-[#BF2929]">AI</span></h1><div class="h-12 w-px bg-[#8B0000]/30"></div><p class="hidden md:block text-xl md:text-2xl text-[#BF2929] font-italiana tracking-wide">AI, ETHICS <span class="text-[#BF2929]">&amp;</span> SOCIETY</p></div><p class="text-sm md:text-base text-black font-caudex uppercase px-8"></p></div><div class="mt-2 relative w-full"><div class="border-t-[3px] border-black absolute top-0 left-0 right-0"></div><div class="border-t border-black absolute top-1 left-0 right-0"></div><div class="py-3"><p class="text-base md:text-lg text-black leading-relaxed font-light px-8">We bring curious people exploring interdisciplinary challenges of the ethics and societal impacts of AI, together.</p></div><div class="border-b border-black absolute bottom-1 left-0 right-0"></div><div class="border-b-[3px] border-black absolute bottom-0 left-0 right-0"></div></div></div><div class="bg-black"><div class="max-w-[1440px] mx-auto bg-white min-h-screen"><article style="padding:48px 60px"><h2 class="mb-8 text-[32px] md:text-[64px]" style="color:#000;font-family:Inter, sans-serif;font-style:normal;font-weight:700;line-height:normal;letter-spacing:-1.28px">A Brief Introduction to AI Ethics</h2><p class="mb-6 text-[12px] md:text-[18px]" style="color:rgba(0, 0, 0, 0.65);font-family:Inter, sans-serif;font-style:normal;font-weight:500;line-height:150%">by <!-- -->Kassidy McDonald and Shirley Zhang</p><p class="mb-12 text-[18px] md:text-[24px]" style="align-self:stretch;color:rgba(0, 0, 0, 0.75);font-family:Inter, sans-serif;font-style:normal;font-weight:400;line-height:150%">From bias and privacy to deepfakes and superintelligence, AI ethics is no longer a niche concern. This piece breaks down why ethical AI matters, how it affects everyday life, and why shaping its future requires voices beyond tech alone.</p><div class="mb-2 rounded-lg overflow-hidden w-full" style="width:1359px;max-width:100%;border-radius:8px;background:#D3D3D3"><img src="/images/blogs/intro-to-ai-ethics.png" alt="A Brief Introduction to AI Ethics" class="w-full h-auto max-w-full" style="display:block;vertical-align:middle"/></div><p class="mb-8" style="color:rgba(0, 0, 0, 0.6);font-family:Inter, sans-serif;font-size:14px;font-style:italic;font-weight:400;line-height:150%">Photo by Danny Choi</p><p class="mb-8" style="color:rgba(0, 0, 0, 0.6);font-family:Inter, sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:150%">January 27, 2026</p><div class="blog-content text-[16px] md:text-[20px]" style="width:1359px;max-width:100%;color:#000;font-family:Inter, sans-serif;font-style:normal;font-weight:500;line-height:150%;margin-bottom:300px">Artificial intelligence (AI) has touched nearly every aspect of our personal and professional lives, making its presence increasingly inescapable. From recommendation systems to large language models (LLMs), many of these applications are opportunistic, and many genuinely beneficial. Insights about computation came from asking philosophical questions, we must also ask the same about the computability and intelligence of modern AI systems [3]. While we recognize the potential of these technologies, we must also maintain a balanced perspective on their emergence and advancement. This requires thoughtfully approaching AI development and fully considering the trajectory of both its limitations and possibilities [15]. <br><br>Professor Steven Coyne brings a uniquely interdisciplinary perspective to these conversations. He earned a Bachelor of Science degree in Mathematics alongside an Honours Bachelor of Arts in Philosophy, and now teaches philosophy with a particular interest in reason and morality. Steven is cross-appointed with the Department of Computer Science and the Department of Philosophy, and he also prepares and delivers ethics modules for the Embedded Ethics Education Initiative (E3I) at the University of Toronto (UofT) [6].<br><br>E3I has become a cornerstone for the UofT‚Äôs computer science curriculum for its aim towards instilling the skills and incentive to incorporate ethical considerations in future educators, scientists, and tech developers [8]. This arises from discussions and concerns that the field of computer science has often overlooked context-sensitive and culturally appropriate technology, exposing the field‚Äôs unchecked hubris [2]. <br><br>Ethical AI has been identified as a critical component of responsible system design because technology alone cannot address the societal consequences of AI. ACM FAccT calls for "an increased focus on ethical analysis grounded in concrete use-cases, people‚Äôs experiences, and applications‚Äù [2]. This reveals that consideration of ethics should be <strong>embedded</strong> in the context of AI systems' operation, and not treated as an afterthought. <br><br><h1>What is AI Ethics?</h1> <br>AI and LLMs must be trained on large datasets in order to effectively carry out their function. Training on datasets consisting of audio, text, and image/video to recognize patterns and make patterns is its hubris. The scale and design of training does not guarantee that the system will treat all users equally. AI ethics confront the biases and ways of discrimination that emerge in these systems because the developers who build them, alongside the data they rely on, are shaped by particular cultural, social, and historical perspectives thereby resulting in these tools reproducing the same assumptions. This creates blind spots. AI ethics, in this sense, is the employment of values and principles that are widely accepted standards of right and wrong to guide moral conduct in developing and using AI [9]. <br><br><strong>Short-term questions.</strong> Steven approaches AI ethics with an understanding that this field can be divided into two halves. The first involves short-term questions about how AI is used today. Are current AI systems biased or discriminatory in the decisions they make about people? <br><br>Virginia Eubanks‚Äô Automating Inequality argues that automated decision-making, in the context of US public services, profiles and punishes the poor. This trend operates on a larger scale, using complex technology and algorithms that blurs the decision-making process, and flawed metrics embed existing social biases into the system, to which she represents as a "digital poorhouse.‚Äù The utilization of high-tech tools such as AI are the new digital infrastructure for continuing historical civil rights problems of class and race-based inequalities. [1, pg 142]<br><br>We must also address issues such as bias, deepfakes, and misinformation as they also require insight and knowledge from disciplines outside of computer science to gain a deeper understanding of what bias and discrimination are and why it is wrong. We, of course, understand why bias instilled in AI systems are harmful, what we may need to further study is the <strong>consequences</strong> it will have on fairness for all [4].<br><br><strong>Long-term questions.</strong> The second half concerns long-term questions about issues of AI safety, particularly debates about artificial general intelligence (AGI) and what may happen when AI systems reach or surpass human-level intelligence and potentially outperform humans [16]. Considering such possibilities like this makes us question how we understand our own contributions to writing, thinking, and other intellectual activities.<br><br>AI ethics requires asking existential questions about human replacement, responsibility, and even possibly survival. If superintelligent AI systems do not need humanity thereby operating independently from human needs and interests, should we focus on preserving human existence in the future? And if these systems can essentially outthink us, does that mean they have reached a form of consciousness [16]? <br><br>Long-term questions about AI push us to contemplate these challenges that AI poses, especially as our reliance on this technology increases. There is a reason there is a contentious debate about whether we will witness the advent of superintelligent AI because it would be hard to maintain control over such systems if they exceeded human intelligence. There is also the issue of whether a superintelligent AI would even share the same values as humans or diverge from them in ways that create conflict instead of alignment.<br><br><h1>AI Ethics Affects Us All</h1><br>Ethical AI is not just a topic for computer scientists, developers, and researchers to be concerned about. AI is woven into nearly every part of life; whether we use it directly through large language models or generative AI tools, or feel their effects as corporations continue to embed AI into day-to-day processes, it is certainly a constant presence in our daily lives.<br><br><strong>Bias.</strong> One of the most heavily discussed ethical AI considerations is bias. As AI systems are trained on increasingly massive amounts of data, it becomes harder for AI to separate useful inferences from the societal biases embedded in historical data. Consequently, these biases become encoded in AI algorithms, which perpetuate and amplify discriminatory outcomes and impact the meritocracy of critical areas such as hiring, criminal justice, and resource allocation. These concerns aren‚Äôt baseless: an AI system‚Äôs hiring algorithm might learn and perpetuate biases when screening job applicants, inadvertently discriminating against and disqualifying qualified candidates. For example, a 2024 study found that "resumes with Black male names are only preferred to Black female names and White male names in 14.8% and 0% of bias tests, respectively‚Äù [4]. Even healthcare algorithms might systematically underestimate the needs of and produce inaccurate results for patients of colour, as another study found that "CNNs that provide high accuracy in skin lesion classification are often trained with images of skin lesion samples of white patients, using datasets in which the estimated proportion of Black patients is approximately 5% to 10%‚Äù which meant that "when tested with images of Black patients, the networks have approximately half the diagnostic accuracy [as] originally claimed‚Äù [5]. These findings highlight that biased AI systems have tangible consequences that can quickly become more persistent, widespread, and harmful to us all.<br><br><strong>Privacy.</strong> Another universal ethical consideration is privacy. With modern AI‚Äôs dependency on the availability and volumes of personal data, even the simple act of accessing the internet raises ethical concern about data access and consent. Personal data that was once collected to tailor recommendations could now be repurposed to train AI systems [17], and data breaches are becoming more prevalent than ever. Stanford‚Äôs 2025 AI index found that "AI incidents jumped by 56.4% in a single year, [with incidents spanning] from data breaches to algorithmic failures that compromise sensitive information‚Äù. With growing concerns, this raises the fundamental question: "Who has the right to say what is allowed and what is not‚Äù [18]? When our data shapes the systems that shape our world, it is motivation for everyone, regardless of background or discipline, to join the conversation. <br><br><strong>Trust.</strong> Trust in information ecosystems has also been destabilized by AI-driven media manipulation. Nancy Pelosi, former House Speaker, was once included in a deepfake controversy that spread doctored videos of her in a seemingly impaired state in 2019 [11]. Though at the time, deepfakes were understood as low-tech media and still fooled many, its implications of altering an individual's speech and behaviour for the purpose of furthering an agenda was always at the forefront of deepfakes. Facebook, now part of Meta,  did not have a policy against this type of distribution of media and now removes such misleading videos, which has also shown us how our perception of deepfakes were only technical and not social which also led to an underdevelopment of digital literacy around manipulated media [12].<br><br>In short, ethical AI isn‚Äôt niche, nor is it insignificant. It‚Äôs personal, and it affects everyone.<br><br><h1>Your perspective matters.</h1><br>Beyond the technical work of computer scientists who implement and design these systems, "AI ethics conversations require participation from people across the disciplinary spectrum‚Äù, as we cannot begin to meaningfully address ethical AI until we understand "how people interact with AI systems‚Äù (Prof. Coyne). <br>While computer scientists and researchers may lay the groundwork for building and deploying AI systems, the "development of ethical AI is not just a technological challenge‚Äù. It involves "navigating complex social, philosophical, and legal questions‚Äù [19], which means that ethical AI can‚Äôt be approached or solved from a technical angle alone. Decisions regarding what data to use, which values to prioritize, and what risks are acceptable cannot be made by one group alone. They are reflections of social, cultural, and moral judgements that require different perspectives across disciplines.<br><br>This is where diversity becomes essential. Philosophers can help to articulate the meanings of terms such as "fairness‚Äù and "harm‚Äù or question why humans make certain decisions, which can also be reflected in how machines should think or make decisions when it comes to humans. Opinions of legal experts, who ensure that AI systems comply with laws and regulations, may help to shape the policies and regulations that will protect our rights. Social scientists can contribute insights into human-AI interaction, or explore AI‚Äôs impact on society and culture. Even fields that seem far removed from the AI conversation bring valuable insights; healthcare workers may have a deeper understanding of AI‚Äôs patient biases through firsthand experiences, and educators may witness its effects on younger generations. <br><br>In other words, it is evident that ethical AI requires more than technical skill and advancements; achieving productive conversations requires a collective and diverse understanding of how these systems shape our society, and how we can shape them in return.<br><br><h1>How can you get involved?</h1><br>If you are new to AI systems and the ethics we must consider in their implementation, development, and use, Steven suggests finding something that connects to your personal interests. For example, if you have an interest in art, you might question the ethics of relying on AI for generated art. The Toronto Maple Leafs received backlash on X for posting perceivably AI-generated content depicting the teams‚Äô Legend‚Äôs Row statues coming to life [13]. The video showcased the incorrect logos and misspellings which did not sit right with hockey fans due to its perception to many as an unethical form of media. <br><br>Explore how your personal interests intersect with the field of AI and how it may be affected by the issues raised because different issues may attract your attention and have the potential to take action. Scouring social media about topics related to the use of AI and its potential implications is a great way to start gauging your interest in particular topics as well as your level of knowledge about a particular concept of AI. <br><br>Schwartz Reisman Institute for Technology and Society at UofT hosts various talks, workshops, and regular seminar series all of which they record and post on their YouTube channel [10]. Steven suggests browsing their library as one may strike your interest. <br><br>Alternatively, you may already have a background in AI and if you are interested in getting more involved in AI ethics, consider registering in courses that help build systematic ways of AI ethics and fill potential gaps you have about AI knowledge. <br><br>Here at UofT, there is PHL277 (‚ÄòData Ethics‚Äô) taught by Steven Coyne himself, which introduces the ethical problems posed by Big Data and algorithmic decision-making by considering concerns about AI ethics [7]. There are more courses in the Philosophy department that consider long-term, big pictures questions like human existentialism, as well as courses in the Computer Science department like CSC300 (‚ÄòComputers and Society‚Äô). <br><br>The best way to discover your particular interest or niche in AI, whether you are starting out or deepening your knowledge, is finding like-minded people who want to discuss AI ethics. Consider finding an extracurricular club of other students in similar positions who want to talk about these issues.<br><br><strong>Where Do We Go From Here?</strong><br>The lingering question remains, where do we go from here? The field of AI is evolving and the technology that rises from it is innovative and transformative but it is also uncharted territory which necessitates further discussion of its development, deployment, and use to ensure it is ethical. Steven is featured on the first of many videos from IlluminAI with different speakers and different topics, and more opportunities to join the conversation on AI ethics. Stay tuned. <br><br><h1>REFERENCES</h1><br><strong>[1]</strong> Eubanks, V. (2018). Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor. St. Martin‚Äôs Press.<br><a href="https://tetrazolelover.at.ua/virginia_eubanks-automating_inequality-how_high-te.pdf" target="_blank" rel="noopener noreferrer">https://tetrazolelover.at.ua/virginia_eubanks-automating_inequality-how_high-te.pdf</a><br><strong>[2]</strong> D‚ÄôIgnazio, C., & Klein, L. F. (2024). Data Feminism for AI. ACM FAccT Conference.<br><a href="https://facctconference.org/static/papers24/facct24-7.pdf" target="_blank" rel="noopener noreferrer">https://facctconference.org/static/papers24/facct24-7.pdf</a><br><strong>[3]</strong> Schrage, M., & Kiron, D. (2025). Philosophy Eats AI. MIT Sloan Management Review.<br><a href="https://sloanreview.mit.edu/article/philosophy-eats-ai/" target="_blank" rel="noopener noreferrer">https://sloanreview.mit.edu/article/philosophy-eats-ai/</a><br><strong>[4]</strong> View of Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval.<br><strong>[5]</strong> Using Artificial Intelligence on Dermatology Conditions in Uganda: A Case for Diversity in Training Data Sets for Machine Learning. bioRxiv.<br><strong>[6]</strong> Embedded Ethics Education Initiative (E3I), University of Toronto.<br><a href="https://www.cs.toronto.edu/embedded-ethics/about.html" target="_blank" rel="noopener noreferrer">https://www.cs.toronto.edu/embedded-ethics/about.html</a><br><strong>[7]</strong> University of Toronto Faculty of Arts & Science. PHL277H1 ‚Äì Data Ethics.<br><a href="https://artsci.calendar.utoronto.ca/course/phl277h1" target="_blank" rel="noopener noreferrer">https://artsci.calendar.utoronto.ca/course/phl277h1</a><br><strong>[8]</strong> University of Toronto. U of T CS Ethics Education Initiative Recognized with D2L Innovation Award.<br><a href="https://web.cs.toronto.edu/news-events/news/u-of-t-cs-ethics-education-initiative-recognized-with-prestigious-d2l-innovation-award-in-teaching-and-learning" target="_blank" rel="noopener noreferrer">https://web.cs.toronto.edu/news-events/news/u-of-t-cs-ethics-education-initiative-recognized-with-prestigious-d2l-innovation-award-in-teaching-and-learning</a><br><strong>[9]</strong> ISO. Responsible AI and Ethics.<br><a href="https://www.iso.org/artificial-intelligence/responsible-ai-ethics" target="_blank" rel="noopener noreferrer">https://www.iso.org/artificial-intelligence/responsible-ai-ethics</a><br><strong>[10]</strong> Schwartz Reisman Institute for Technology & Society (YouTube).<br><a href="https://www.youtube.com/c/SchwartzReismanInstitute" target="_blank" rel="noopener noreferrer">https://www.youtube.com/c/SchwartzReismanInstitute</a><br><strong>[11]</strong> CBS News. Doctored Nancy Pelosi Video Highlights Threat of Deepfake Tech (2019).<br><a href="https://www.cbsnews.com/news/doctored-nancy-pelosi-video-highlights-threat-of-deepfake-tech-2019-05-25/" target="_blank" rel="noopener noreferrer">https://www.cbsnews.com/news/doctored-nancy-pelosi-video-highlights-threat-of-deepfake-tech-2019-05-25/</a><br><strong>[12]</strong> Euronews. Does Facebook‚Äôs New Policy on Deepfake Videos Go Far Enough? (2020).<br><a href="https://www.euronews.com/my-europe/2020/01/07/does-facebook-s-new-policy-on-deepfake-videos-go-far-enough-thecube" target="_blank" rel="noopener noreferrer">https://www.euronews.com/my-europe/2020/01/07/does-facebook-s-new-policy-on-deepfake-videos-go-far-enough-thecube</a><br><strong>[13]</strong> Hockey Patrol. Fans React After Maple Leafs Use AI in 2025‚Äì26 Season Hype Video.<br><a href="https://www.hockeypatrol.com/nhl-team/toronto-maple-leafs/fans-react-after-maple-leafs-use-ai-in-2025-26-season-hype-video" target="_blank" rel="noopener noreferrer">https://www.hockeypatrol.com/nhl-team/toronto-maple-leafs/fans-react-after-maple-leafs-use-ai-in-2025-26-season-hype-video</a><br><strong>[14]</strong> Toronto Star. These Ads Near Union Station Could Be Recording You.<br><a href="https://www.thestar.com/news/gta/these-ads-near-union-station-and-other-places-around-toronto-could-be-recording-you-what/article_7af7c920-1ce7-4b19-98db-4c22d742f202.html" target="_blank" rel="noopener noreferrer">https://www.thestar.com/news/gta/these-ads-near-union-station-and-other-places-around-toronto-could-be-recording-you-what/article_7af7c920-1ce7-4b19-98db-4c22d742f202.html</a><br><strong>[15]</strong> IBM Think. Examining Superintelligence.<br><a href="https://www.ibm.com/think/insights/examining-superintelligence" target="_blank" rel="noopener noreferrer">https://www.ibm.com/think/insights/examining-superintelligence</a><br><strong>[16]</strong> Towards Data Science. Stop Worrying About AGI ‚Äî The Immediate Danger Is Reduced General Intelligence.<br><a href="https://towardsdatascience.com/stop-worrying-about-agi-the-immediate-danger-is-reduced-general-intelligence-rgi/" target="_blank" rel="noopener noreferrer">https://towardsdatascience.com/stop-worrying-about-agi-the-immediate-danger-is-reduced-general-intelligence-rgi/</a><br><strong>[17]</strong> Stanford HAI. Privacy in an AI Era: How Do We Protect Our Personal Information?<br><strong>[18]</strong> Harvard Division of Continuing Education. Ethics in AI: Why It Matters.<br><a href="https://professional.dce.harvard.edu/blog/ethics-in-ai-why-it-matters/" target="_blank" rel="noopener noreferrer">https://professional.dce.harvard.edu/blog/ethics-in-ai-why-it-matters/</a><br><strong>[19]</strong> Why Is Interdisciplinary Collaboration Essential for AI Ethics?</div><div style="width:100%;height:3px;background:#000;margin-bottom:48px"></div><section><h2 class="mb-12" style="width:625px;color:#000;font-family:Inter, sans-serif;font-size:40px;font-style:normal;font-weight:600;line-height:110%">Read More</h2><div class="inline-flex items-start" style="gap:32px"><a class="flex flex-col gap-4 no-underline group" style="flex:1 0 0;align-self:stretch" href="/blogs/letter-from-illuminai/"><div class="rounded-lg overflow-hidden" style="width:100%;aspect-ratio:4 / 3;background:#F7F7F7;position:relative"><img src="/images/blogs/letter-from-illuminai.png" alt="üíå Letter From illuminAI" class="w-full h-full object-cover group-hover:scale-105 transition-transform duration-300"/></div><div class="flex flex-col gap-1"><h3 class="line-clamp-2" style="color:#000;font-family:Inter, sans-serif;font-size:20px;font-weight:500;line-height:150%">üíå Letter From illuminAI</h3><p style="color:#828282;font-family:Inter, sans-serif;font-size:20px;font-weight:500;line-height:150%">By <!-- -->illuminAI Executive Team</p></div></a></div></section></article></div></div></main><script src="https://illuminaite.github.io/_next/static/chunks/webpack-b3042b0fdd2346c1.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"a:\"$Sreact.fragment\"\nb:I[9275,[],\"\"]\nc:I[1343,[],\"\"]\ne:I[3120,[],\"OutletBoundary\"]\n10:I[3120,[],\"MetadataBoundary\"]\n12:I[3120,[],\"ViewportBoundary\"]\n14:I[6130,[],\"\"]\n1:HL[\"https://illuminaite.github.io/_next/static/media/111c93f1bc244164-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"https://illuminaite.github.io/_next/static/media/828e2958d60bafae-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"https://illuminaite.github.io/_next/static/media/acaa31bcd8de99a2-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n4:HL[\"https://illuminaite.github.io/_next/static/media/b7ae23d8a9c319da-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n5:HL[\"https://illuminaite.github.io/_next/static/media/c8802c19af58d4c3-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n6:HL[\"https://illuminaite.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n7:HL[\"https://illuminaite.github.io/_next/static/media/f18367e159541896-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n8:HL[\"https://illuminaite.github.io/_next/static/css/855e81ff297effac.css\",\"style\"]\n9:HL[\"https://illuminaite.github.io/_next/static/css/ce2246e58b109e16.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"iYL_uAzetNe7Ei6yBEkwQ\",\"p\":\"https://illuminaite.github.io\",\"c\":[\"\",\"blogs\",\"intro-to-ai-ethics\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blogs\",{\"children\":[[\"slug\",\"intro-to-ai-ethics\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"intro-to-ai-ethics\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$a\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"https://illuminaite.github.io/_next/static/css/855e81ff297effac.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"https://illuminaite.github.io/_next/static/css/ce2246e58b109e16.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_0dcb31 __variable_d47d9e __variable_69257b __variable_ccf310 __variable_b278cd\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://use.fontawesome.com/releases/v5.14.0/css/all.css\",\"integrity\":\"sha384-HzLeBuhoNPvSl5KYnjx0BT+WB0QEEqLprO+NBkkk5gbc67FTaL7XIGa2w1L0Xbgc\",\"crossOrigin\":\"anonymous\"}]}],[\"$\",\"body\",null,{\"className\":\"__className_0dcb31 font-karla antialiased bg-black min-h-screen flex justify-center px-[1px] py-[1px]\",\"children\":[\"$\",\"main\",null,{\"className\":\"w-full max-w-[1400px] bg-white min-h-fit shadow-[0_0_0_1px_#000]\",\"children\":[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}]}]]}]]}],{\"children\":[\"blogs\",[\"$\",\"$a\",\"c\",{\"children\":[null,[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blogs\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"intro-to-ai-ethics\",\"d\"],[\"$\",\"$a\",\"c\",{\"children\":[null,[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blogs\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$a\",\"c\",{\"children\":[\"$Ld\",null,[\"$\",\"$Le\",null,{\"children\":\"$Lf\"}]]}],{},null]},null]},null]},null],[\"$\",\"$a\",\"h\",{\"children\":[null,[\"$\",\"$a\",\"Jbnz4Hon6tRZpx0MlCvuQ\",{\"children\":[[\"$\",\"$L10\",null,{\"children\":\"$L11\"}],[\"$\",\"$L12\",null,{\"children\":\"$L13\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\"}]]}]]}]]],\"m\":\"$undefined\",\"G\":\"$14\",\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"15:I[552,[\"231\",\"static/chunks/231-6b28840e4f5e2501.js\",\"688\",\"static/chunks/app/blogs/%5Bslug%5D/page-465cbca8ec132ab4.js\"],\"default\",1]\n16:I[8871,[\"231\",\"static/chunks/231-6b28840e4f5e2501.js\",\"688\",\"static/chunks/app/blogs/%5Bslug%5D/page-465cbca8ec132ab4.js\"],\"default\",1]\n17:I[8319,[\"231\",\"static/chunks/231-6b28840e4f5e2501.js\",\"688\",\"static/chunks/app/blogs/%5Bslug%5D/page-465cbca8ec132ab4.js\"],\"default\",1]\n18:T4d82,"])</script><script>self.__next_f.push([1,"Artificial intelligence (AI) has touched nearly every aspect of our personal and professional lives, making its presence increasingly inescapable. From recommendation systems to large language models (LLMs), many of these applications are opportunistic, and many genuinely beneficial. Insights about computation came from asking philosophical questions, we must also ask the same about the computability and intelligence of modern AI systems [3]. While we recognize the potential of these technologies, we must also maintain a balanced perspective on their emergence and advancement. This requires thoughtfully approaching AI development and fully considering the trajectory of both its limitations and possibilities [15]. \n\nProfessor Steven Coyne brings a uniquely interdisciplinary perspective to these conversations. He earned a Bachelor of Science degree in Mathematics alongside an Honours Bachelor of Arts in Philosophy, and now teaches philosophy with a particular interest in reason and morality. Steven is cross-appointed with the Department of Computer Science and the Department of Philosophy, and he also prepares and delivers ethics modules for the Embedded Ethics Education Initiative (E3I) at the University of Toronto (UofT) [6].\n\nE3I has become a cornerstone for the UofT‚Äôs computer science curriculum for its aim towards instilling the skills and incentive to incorporate ethical considerations in future educators, scientists, and tech developers [8]. This arises from discussions and concerns that the field of computer science has often overlooked context-sensitive and culturally appropriate technology, exposing the field‚Äôs unchecked hubris [2]. \n\nEthical AI has been identified as a critical component of responsible system design because technology alone cannot address the societal consequences of AI. ACM FAccT calls for \"an increased focus on ethical analysis grounded in concrete use-cases, people‚Äôs experiences, and applications‚Äù [2]. This reveals that consideration of ethics should be \u003cstrong\u003eembedded\u003c/strong\u003e in the context of AI systems' operation, and not treated as an afterthought. \n\n\u003ch1\u003eWhat is AI Ethics?\u003c/h1\u003e \nAI and LLMs must be trained on large datasets in order to effectively carry out their function. Training on datasets consisting of audio, text, and image/video to recognize patterns and make patterns is its hubris. The scale and design of training does not guarantee that the system will treat all users equally. AI ethics confront the biases and ways of discrimination that emerge in these systems because the developers who build them, alongside the data they rely on, are shaped by particular cultural, social, and historical perspectives thereby resulting in these tools reproducing the same assumptions. This creates blind spots. AI ethics, in this sense, is the employment of values and principles that are widely accepted standards of right and wrong to guide moral conduct in developing and using AI [9]. \n\n\u003cstrong\u003eShort-term questions.\u003c/strong\u003e Steven approaches AI ethics with an understanding that this field can be divided into two halves. The first involves short-term questions about how AI is used today. Are current AI systems biased or discriminatory in the decisions they make about people? \n\nVirginia Eubanks‚Äô Automating Inequality argues that automated decision-making, in the context of US public services, profiles and punishes the poor. This trend operates on a larger scale, using complex technology and algorithms that blurs the decision-making process, and flawed metrics embed existing social biases into the system, to which she represents as a \"digital poorhouse.‚Äù The utilization of high-tech tools such as AI are the new digital infrastructure for continuing historical civil rights problems of class and race-based inequalities. [1, pg 142]\n\nWe must also address issues such as bias, deepfakes, and misinformation as they also require insight and knowledge from disciplines outside of computer science to gain a deeper understanding of what bias and discrimination are and why it is wrong. We, of course, understand why bias instilled in AI systems are harmful, what we may need to further study is the \u003cstrong\u003econsequences\u003c/strong\u003e it will have on fairness for all [4].\n\n\u003cstrong\u003eLong-term questions.\u003c/strong\u003e The second half concerns long-term questions about issues of AI safety, particularly debates about artificial general intelligence (AGI) and what may happen when AI systems reach or surpass human-level intelligence and potentially outperform humans [16]. Considering such possibilities like this makes us question how we understand our own contributions to writing, thinking, and other intellectual activities.\n\nAI ethics requires asking existential questions about human replacement, responsibility, and even possibly survival. If superintelligent AI systems do not need humanity thereby operating independently from human needs and interests, should we focus on preserving human existence in the future? And if these systems can essentially outthink us, does that mean they have reached a form of consciousness [16]? \n\nLong-term questions about AI push us to contemplate these challenges that AI poses, especially as our reliance on this technology increases. There is a reason there is a contentious debate about whether we will witness the advent of superintelligent AI because it would be hard to maintain control over such systems if they exceeded human intelligence. There is also the issue of whether a superintelligent AI would even share the same values as humans or diverge from them in ways that create conflict instead of alignment.\n\n\u003ch1\u003eAI Ethics Affects Us All\u003c/h1\u003e\nEthical AI is not just a topic for computer scientists, developers, and researchers to be concerned about. AI is woven into nearly every part of life; whether we use it directly through large language models or generative AI tools, or feel their effects as corporations continue to embed AI into day-to-day processes, it is certainly a constant presence in our daily lives.\n\n\u003cstrong\u003eBias.\u003c/strong\u003e One of the most heavily discussed ethical AI considerations is bias. As AI systems are trained on increasingly massive amounts of data, it becomes harder for AI to separate useful inferences from the societal biases embedded in historical data. Consequently, these biases become encoded in AI algorithms, which perpetuate and amplify discriminatory outcomes and impact the meritocracy of critical areas such as hiring, criminal justice, and resource allocation. These concerns aren‚Äôt baseless: an AI system‚Äôs hiring algorithm might learn and perpetuate biases when screening job applicants, inadvertently discriminating against and disqualifying qualified candidates. For example, a 2024 study found that \"resumes with Black male names are only preferred to Black female names and White male names in 14.8% and 0% of bias tests, respectively‚Äù [4]. Even healthcare algorithms might systematically underestimate the needs of and produce inaccurate results for patients of colour, as another study found that \"CNNs that provide high accuracy in skin lesion classification are often trained with images of skin lesion samples of white patients, using datasets in which the estimated proportion of Black patients is approximately 5% to 10%‚Äù which meant that \"when tested with images of Black patients, the networks have approximately half the diagnostic accuracy [as] originally claimed‚Äù [5]. These findings highlight that biased AI systems have tangible consequences that can quickly become more persistent, widespread, and harmful to us all.\n\n\u003cstrong\u003ePrivacy.\u003c/strong\u003e Another universal ethical consideration is privacy. With modern AI‚Äôs dependency on the availability and volumes of personal data, even the simple act of accessing the internet raises ethical concern about data access and consent. Personal data that was once collected to tailor recommendations could now be repurposed to train AI systems [17], and data breaches are becoming more prevalent than ever. Stanford‚Äôs 2025 AI index found that \"AI incidents jumped by 56.4% in a single year, [with incidents spanning] from data breaches to algorithmic failures that compromise sensitive information‚Äù. With growing concerns, this raises the fundamental question: \"Who has the right to say what is allowed and what is not‚Äù [18]? When our data shapes the systems that shape our world, it is motivation for everyone, regardless of background or discipline, to join the conversation. \n\n\u003cstrong\u003eTrust.\u003c/strong\u003e Trust in information ecosystems has also been destabilized by AI-driven media manipulation. Nancy Pelosi, former House Speaker, was once included in a deepfake controversy that spread doctored videos of her in a seemingly impaired state in 2019 [11]. Though at the time, deepfakes were understood as low-tech media and still fooled many, its implications of altering an individual's speech and behaviour for the purpose of furthering an agenda was always at the forefront of deepfakes. Facebook, now part of Meta,  did not have a policy against this type of distribution of media and now removes such misleading videos, which has also shown us how our perception of deepfakes were only technical and not social which also led to an underdevelopment of digital literacy around manipulated media [12].\n\nIn short, ethical AI isn‚Äôt niche, nor is it insignificant. It‚Äôs personal, and it affects everyone.\n\n\u003ch1\u003eYour perspective matters.\u003c/h1\u003e\nBeyond the technical work of computer scientists who implement and design these systems, \"AI ethics conversations require participation from people across the disciplinary spectrum‚Äù, as we cannot begin to meaningfully address ethical AI until we understand \"how people interact with AI systems‚Äù (Prof. Coyne). \nWhile computer scientists and researchers may lay the groundwork for building and deploying AI systems, the \"development of ethical AI is not just a technological challenge‚Äù. It involves \"navigating complex social, philosophical, and legal questions‚Äù [19], which means that ethical AI can‚Äôt be approached or solved from a technical angle alone. Decisions regarding what data to use, which values to prioritize, and what risks are acceptable cannot be made by one group alone. They are reflections of social, cultural, and moral judgements that require different perspectives across disciplines.\n\nThis is where diversity becomes essential. Philosophers can help to articulate the meanings of terms such as \"fairness‚Äù and \"harm‚Äù or question why humans make certain decisions, which can also be reflected in how machines should think or make decisions when it comes to humans. Opinions of legal experts, who ensure that AI systems comply with laws and regulations, may help to shape the policies and regulations that will protect our rights. Social scientists can contribute insights into human-AI interaction, or explore AI‚Äôs impact on society and culture. Even fields that seem far removed from the AI conversation bring valuable insights; healthcare workers may have a deeper understanding of AI‚Äôs patient biases through firsthand experiences, and educators may witness its effects on younger generations. \n\nIn other words, it is evident that ethical AI requires more than technical skill and advancements; achieving productive conversations requires a collective and diverse understanding of how these systems shape our society, and how we can shape them in return.\n\n\u003ch1\u003eHow can you get involved?\u003c/h1\u003e\nIf you are new to AI systems and the ethics we must consider in their implementation, development, and use, Steven suggests finding something that connects to your personal interests. For example, if you have an interest in art, you might question the ethics of relying on AI for generated art. The Toronto Maple Leafs received backlash on X for posting perceivably AI-generated content depicting the teams‚Äô Legend‚Äôs Row statues coming to life [13]. The video showcased the incorrect logos and misspellings which did not sit right with hockey fans due to its perception to many as an unethical form of media. \n\nExplore how your personal interests intersect with the field of AI and how it may be affected by the issues raised because different issues may attract your attention and have the potential to take action. Scouring social media about topics related to the use of AI and its potential implications is a great way to start gauging your interest in particular topics as well as your level of knowledge about a particular concept of AI. \n\nSchwartz Reisman Institute for Technology and Society at UofT hosts various talks, workshops, and regular seminar series all of which they record and post on their YouTube channel [10]. Steven suggests browsing their library as one may strike your interest. \n\nAlternatively, you may already have a background in AI and if you are interested in getting more involved in AI ethics, consider registering in courses that help build systematic ways of AI ethics and fill potential gaps you have about AI knowledge. \n\nHere at UofT, there is PHL277 (‚ÄòData Ethics‚Äô) taught by Steven Coyne himself, which introduces the ethical problems posed by Big Data and algorithmic decision-making by considering concerns about AI ethics [7]. There are more courses in the Philosophy department that consider long-term, big pictures questions like human existentialism, as well as courses in the Computer Science department like CSC300 (‚ÄòComputers and Society‚Äô). \n\nThe best way to discover your particular interest or niche in AI, whether you are starting out or deepening your knowledge, is finding like-minded people who want to discuss AI ethics. Consider finding an extracurricular club of other students in similar positions who want to talk about these issues.\n\n\u003cstrong\u003eWhere Do We Go From Here?\u003c/strong\u003e\nThe lingering question remains, where do we go from here? The field of AI is evolving and the technology that rises from it is innovative and transformative but it is also uncharted territory which necessitates further discussion of its development, deployment, and use to ensure it is ethical. Steven is featured on the first of many videos from IlluminAI with different speakers and different topics, and more opportunities to join the conversation on AI ethics. Stay tuned. \n\n\u003ch1\u003eREFERENCES\u003c/h1\u003e\n\u003cstrong\u003e[1]\u003c/strong\u003e Eubanks, V. (2018). Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor. St. Martin‚Äôs Press.\n\u003ca href=\"https://tetrazolelover.at.ua/virginia_eubanks-automating_inequality-how_high-te.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://tetrazolelover.at.ua/virginia_eubanks-automating_inequality-how_high-te.pdf\u003c/a\u003e\n\u003cstrong\u003e[2]\u003c/strong\u003e D‚ÄôIgnazio, C., \u0026 Klein, L. F. (2024). Data Feminism for AI. ACM FAccT Conference.\n\u003ca href=\"https://facctconference.org/static/papers24/facct24-7.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://facctconference.org/static/papers24/facct24-7.pdf\u003c/a\u003e\n\u003cstrong\u003e[3]\u003c/strong\u003e Schrage, M., \u0026 Kiron, D. (2025). Philosophy Eats AI. MIT Sloan Management Review.\n\u003ca href=\"https://sloanreview.mit.edu/article/philosophy-eats-ai/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://sloanreview.mit.edu/article/philosophy-eats-ai/\u003c/a\u003e\n\u003cstrong\u003e[4]\u003c/strong\u003e View of Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval.\n\u003cstrong\u003e[5]\u003c/strong\u003e Using Artificial Intelligence on Dermatology Conditions in Uganda: A Case for Diversity in Training Data Sets for Machine Learning. bioRxiv.\n\u003cstrong\u003e[6]\u003c/strong\u003e Embedded Ethics Education Initiative (E3I), University of Toronto.\n\u003ca href=\"https://www.cs.toronto.edu/embedded-ethics/about.html\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.cs.toronto.edu/embedded-ethics/about.html\u003c/a\u003e\n\u003cstrong\u003e[7]\u003c/strong\u003e University of Toronto Faculty of Arts \u0026 Science. PHL277H1 ‚Äì Data Ethics.\n\u003ca href=\"https://artsci.calendar.utoronto.ca/course/phl277h1\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://artsci.calendar.utoronto.ca/course/phl277h1\u003c/a\u003e\n\u003cstrong\u003e[8]\u003c/strong\u003e University of Toronto. U of T CS Ethics Education Initiative Recognized with D2L Innovation Award.\n\u003ca href=\"https://web.cs.toronto.edu/news-events/news/u-of-t-cs-ethics-education-initiative-recognized-with-prestigious-d2l-innovation-award-in-teaching-and-learning\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://web.cs.toronto.edu/news-events/news/u-of-t-cs-ethics-education-initiative-recognized-with-prestigious-d2l-innovation-award-in-teaching-and-learning\u003c/a\u003e\n\u003cstrong\u003e[9]\u003c/strong\u003e ISO. Responsible AI and Ethics.\n\u003ca href=\"https://www.iso.org/artificial-intelligence/responsible-ai-ethics\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.iso.org/artificial-intelligence/responsible-ai-ethics\u003c/a\u003e\n\u003cstrong\u003e[10]\u003c/strong\u003e Schwartz Reisman Institute for Technology \u0026 Society (YouTube).\n\u003ca href=\"https://www.youtube.com/c/SchwartzReismanInstitute\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.youtube.com/c/SchwartzReismanInstitute\u003c/a\u003e\n\u003cstrong\u003e[11]\u003c/strong\u003e CBS News. Doctored Nancy Pelosi Video Highlights Threat of Deepfake Tech (2019).\n\u003ca href=\"https://www.cbsnews.com/news/doctored-nancy-pelosi-video-highlights-threat-of-deepfake-tech-2019-05-25/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.cbsnews.com/news/doctored-nancy-pelosi-video-highlights-threat-of-deepfake-tech-2019-05-25/\u003c/a\u003e\n\u003cstrong\u003e[12]\u003c/strong\u003e Euronews. Does Facebook‚Äôs New Policy on Deepfake Videos Go Far Enough? (2020).\n\u003ca href=\"https://www.euronews.com/my-europe/2020/01/07/does-facebook-s-new-policy-on-deepfake-videos-go-far-enough-thecube\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.euronews.com/my-europe/2020/01/07/does-facebook-s-new-policy-on-deepfake-videos-go-far-enough-thecube\u003c/a\u003e\n\u003cstrong\u003e[13]\u003c/strong\u003e Hockey Patrol. Fans React After Maple Leafs Use AI in 2025‚Äì26 Season Hype Video.\n\u003ca href=\"https://www.hockeypatrol.com/nhl-team/toronto-maple-leafs/fans-react-after-maple-leafs-use-ai-in-2025-26-season-hype-video\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.hockeypatrol.com/nhl-team/toronto-maple-leafs/fans-react-after-maple-leafs-use-ai-in-2025-26-season-hype-video\u003c/a\u003e\n\u003cstrong\u003e[14]\u003c/strong\u003e Toronto Star. These Ads Near Union Station Could Be Recording You.\n\u003ca href=\"https://www.thestar.com/news/gta/these-ads-near-union-station-and-other-places-around-toronto-could-be-recording-you-what/article_7af7c920-1ce7-4b19-98db-4c22d742f202.html\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.thestar.com/news/gta/these-ads-near-union-station-and-other-places-around-toronto-could-be-recording-you-what/article_7af7c920-1ce7-4b19-98db-4c22d742f202.html\u003c/a\u003e\n\u003cstrong\u003e[15]\u003c/strong\u003e IBM Think. Examining Superintelligence.\n\u003ca href=\"https://www.ibm.com/think/insights/examining-superintelligence\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.ibm.com/think/insights/examining-superintelligence\u003c/a\u003e\n\u003cstrong\u003e[16]\u003c/strong\u003e Towards Data Science. Stop Worrying About AGI ‚Äî The Immediate Danger Is Reduced General Intelligence.\n\u003ca href=\"https://towardsdatascience.com/stop-worrying-about-agi-the-immediate-danger-is-reduced-general-intelligence-rgi/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://towardsdatascience.com/stop-worrying-about-agi-the-immediate-danger-is-reduced-general-intelligence-rgi/\u003c/a\u003e\n\u003cstrong\u003e[17]\u003c/strong\u003e Stanford HAI. Privacy in an AI Era: How Do We Protect Our Personal Information?\n\u003cstrong\u003e[18]\u003c/strong\u003e Harvard Division of Continuing Education. Ethics in AI: Why It Matters.\n\u003ca href=\"https://professional.dce.harvard.edu/blog/ethics-in-ai-why-it-matters/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://professional.dce.harvard.edu/blog/ethics-in-ai-why-it-matters/\u003c/a\u003e\n\u003cstrong\u003e[19]\u003c/strong\u003e Why Is Interdisciplinary Collaboration Essential for AI Ethics?"])</script><script>self.__next_f.push([1,"19:T4d82,"])</script><script>self.__next_f.push([1,"Artificial intelligence (AI) has touched nearly every aspect of our personal and professional lives, making its presence increasingly inescapable. From recommendation systems to large language models (LLMs), many of these applications are opportunistic, and many genuinely beneficial. Insights about computation came from asking philosophical questions, we must also ask the same about the computability and intelligence of modern AI systems [3]. While we recognize the potential of these technologies, we must also maintain a balanced perspective on their emergence and advancement. This requires thoughtfully approaching AI development and fully considering the trajectory of both its limitations and possibilities [15]. \n\nProfessor Steven Coyne brings a uniquely interdisciplinary perspective to these conversations. He earned a Bachelor of Science degree in Mathematics alongside an Honours Bachelor of Arts in Philosophy, and now teaches philosophy with a particular interest in reason and morality. Steven is cross-appointed with the Department of Computer Science and the Department of Philosophy, and he also prepares and delivers ethics modules for the Embedded Ethics Education Initiative (E3I) at the University of Toronto (UofT) [6].\n\nE3I has become a cornerstone for the UofT‚Äôs computer science curriculum for its aim towards instilling the skills and incentive to incorporate ethical considerations in future educators, scientists, and tech developers [8]. This arises from discussions and concerns that the field of computer science has often overlooked context-sensitive and culturally appropriate technology, exposing the field‚Äôs unchecked hubris [2]. \n\nEthical AI has been identified as a critical component of responsible system design because technology alone cannot address the societal consequences of AI. ACM FAccT calls for \"an increased focus on ethical analysis grounded in concrete use-cases, people‚Äôs experiences, and applications‚Äù [2]. This reveals that consideration of ethics should be \u003cstrong\u003eembedded\u003c/strong\u003e in the context of AI systems' operation, and not treated as an afterthought. \n\n\u003ch1\u003eWhat is AI Ethics?\u003c/h1\u003e \nAI and LLMs must be trained on large datasets in order to effectively carry out their function. Training on datasets consisting of audio, text, and image/video to recognize patterns and make patterns is its hubris. The scale and design of training does not guarantee that the system will treat all users equally. AI ethics confront the biases and ways of discrimination that emerge in these systems because the developers who build them, alongside the data they rely on, are shaped by particular cultural, social, and historical perspectives thereby resulting in these tools reproducing the same assumptions. This creates blind spots. AI ethics, in this sense, is the employment of values and principles that are widely accepted standards of right and wrong to guide moral conduct in developing and using AI [9]. \n\n\u003cstrong\u003eShort-term questions.\u003c/strong\u003e Steven approaches AI ethics with an understanding that this field can be divided into two halves. The first involves short-term questions about how AI is used today. Are current AI systems biased or discriminatory in the decisions they make about people? \n\nVirginia Eubanks‚Äô Automating Inequality argues that automated decision-making, in the context of US public services, profiles and punishes the poor. This trend operates on a larger scale, using complex technology and algorithms that blurs the decision-making process, and flawed metrics embed existing social biases into the system, to which she represents as a \"digital poorhouse.‚Äù The utilization of high-tech tools such as AI are the new digital infrastructure for continuing historical civil rights problems of class and race-based inequalities. [1, pg 142]\n\nWe must also address issues such as bias, deepfakes, and misinformation as they also require insight and knowledge from disciplines outside of computer science to gain a deeper understanding of what bias and discrimination are and why it is wrong. We, of course, understand why bias instilled in AI systems are harmful, what we may need to further study is the \u003cstrong\u003econsequences\u003c/strong\u003e it will have on fairness for all [4].\n\n\u003cstrong\u003eLong-term questions.\u003c/strong\u003e The second half concerns long-term questions about issues of AI safety, particularly debates about artificial general intelligence (AGI) and what may happen when AI systems reach or surpass human-level intelligence and potentially outperform humans [16]. Considering such possibilities like this makes us question how we understand our own contributions to writing, thinking, and other intellectual activities.\n\nAI ethics requires asking existential questions about human replacement, responsibility, and even possibly survival. If superintelligent AI systems do not need humanity thereby operating independently from human needs and interests, should we focus on preserving human existence in the future? And if these systems can essentially outthink us, does that mean they have reached a form of consciousness [16]? \n\nLong-term questions about AI push us to contemplate these challenges that AI poses, especially as our reliance on this technology increases. There is a reason there is a contentious debate about whether we will witness the advent of superintelligent AI because it would be hard to maintain control over such systems if they exceeded human intelligence. There is also the issue of whether a superintelligent AI would even share the same values as humans or diverge from them in ways that create conflict instead of alignment.\n\n\u003ch1\u003eAI Ethics Affects Us All\u003c/h1\u003e\nEthical AI is not just a topic for computer scientists, developers, and researchers to be concerned about. AI is woven into nearly every part of life; whether we use it directly through large language models or generative AI tools, or feel their effects as corporations continue to embed AI into day-to-day processes, it is certainly a constant presence in our daily lives.\n\n\u003cstrong\u003eBias.\u003c/strong\u003e One of the most heavily discussed ethical AI considerations is bias. As AI systems are trained on increasingly massive amounts of data, it becomes harder for AI to separate useful inferences from the societal biases embedded in historical data. Consequently, these biases become encoded in AI algorithms, which perpetuate and amplify discriminatory outcomes and impact the meritocracy of critical areas such as hiring, criminal justice, and resource allocation. These concerns aren‚Äôt baseless: an AI system‚Äôs hiring algorithm might learn and perpetuate biases when screening job applicants, inadvertently discriminating against and disqualifying qualified candidates. For example, a 2024 study found that \"resumes with Black male names are only preferred to Black female names and White male names in 14.8% and 0% of bias tests, respectively‚Äù [4]. Even healthcare algorithms might systematically underestimate the needs of and produce inaccurate results for patients of colour, as another study found that \"CNNs that provide high accuracy in skin lesion classification are often trained with images of skin lesion samples of white patients, using datasets in which the estimated proportion of Black patients is approximately 5% to 10%‚Äù which meant that \"when tested with images of Black patients, the networks have approximately half the diagnostic accuracy [as] originally claimed‚Äù [5]. These findings highlight that biased AI systems have tangible consequences that can quickly become more persistent, widespread, and harmful to us all.\n\n\u003cstrong\u003ePrivacy.\u003c/strong\u003e Another universal ethical consideration is privacy. With modern AI‚Äôs dependency on the availability and volumes of personal data, even the simple act of accessing the internet raises ethical concern about data access and consent. Personal data that was once collected to tailor recommendations could now be repurposed to train AI systems [17], and data breaches are becoming more prevalent than ever. Stanford‚Äôs 2025 AI index found that \"AI incidents jumped by 56.4% in a single year, [with incidents spanning] from data breaches to algorithmic failures that compromise sensitive information‚Äù. With growing concerns, this raises the fundamental question: \"Who has the right to say what is allowed and what is not‚Äù [18]? When our data shapes the systems that shape our world, it is motivation for everyone, regardless of background or discipline, to join the conversation. \n\n\u003cstrong\u003eTrust.\u003c/strong\u003e Trust in information ecosystems has also been destabilized by AI-driven media manipulation. Nancy Pelosi, former House Speaker, was once included in a deepfake controversy that spread doctored videos of her in a seemingly impaired state in 2019 [11]. Though at the time, deepfakes were understood as low-tech media and still fooled many, its implications of altering an individual's speech and behaviour for the purpose of furthering an agenda was always at the forefront of deepfakes. Facebook, now part of Meta,  did not have a policy against this type of distribution of media and now removes such misleading videos, which has also shown us how our perception of deepfakes were only technical and not social which also led to an underdevelopment of digital literacy around manipulated media [12].\n\nIn short, ethical AI isn‚Äôt niche, nor is it insignificant. It‚Äôs personal, and it affects everyone.\n\n\u003ch1\u003eYour perspective matters.\u003c/h1\u003e\nBeyond the technical work of computer scientists who implement and design these systems, \"AI ethics conversations require participation from people across the disciplinary spectrum‚Äù, as we cannot begin to meaningfully address ethical AI until we understand \"how people interact with AI systems‚Äù (Prof. Coyne). \nWhile computer scientists and researchers may lay the groundwork for building and deploying AI systems, the \"development of ethical AI is not just a technological challenge‚Äù. It involves \"navigating complex social, philosophical, and legal questions‚Äù [19], which means that ethical AI can‚Äôt be approached or solved from a technical angle alone. Decisions regarding what data to use, which values to prioritize, and what risks are acceptable cannot be made by one group alone. They are reflections of social, cultural, and moral judgements that require different perspectives across disciplines.\n\nThis is where diversity becomes essential. Philosophers can help to articulate the meanings of terms such as \"fairness‚Äù and \"harm‚Äù or question why humans make certain decisions, which can also be reflected in how machines should think or make decisions when it comes to humans. Opinions of legal experts, who ensure that AI systems comply with laws and regulations, may help to shape the policies and regulations that will protect our rights. Social scientists can contribute insights into human-AI interaction, or explore AI‚Äôs impact on society and culture. Even fields that seem far removed from the AI conversation bring valuable insights; healthcare workers may have a deeper understanding of AI‚Äôs patient biases through firsthand experiences, and educators may witness its effects on younger generations. \n\nIn other words, it is evident that ethical AI requires more than technical skill and advancements; achieving productive conversations requires a collective and diverse understanding of how these systems shape our society, and how we can shape them in return.\n\n\u003ch1\u003eHow can you get involved?\u003c/h1\u003e\nIf you are new to AI systems and the ethics we must consider in their implementation, development, and use, Steven suggests finding something that connects to your personal interests. For example, if you have an interest in art, you might question the ethics of relying on AI for generated art. The Toronto Maple Leafs received backlash on X for posting perceivably AI-generated content depicting the teams‚Äô Legend‚Äôs Row statues coming to life [13]. The video showcased the incorrect logos and misspellings which did not sit right with hockey fans due to its perception to many as an unethical form of media. \n\nExplore how your personal interests intersect with the field of AI and how it may be affected by the issues raised because different issues may attract your attention and have the potential to take action. Scouring social media about topics related to the use of AI and its potential implications is a great way to start gauging your interest in particular topics as well as your level of knowledge about a particular concept of AI. \n\nSchwartz Reisman Institute for Technology and Society at UofT hosts various talks, workshops, and regular seminar series all of which they record and post on their YouTube channel [10]. Steven suggests browsing their library as one may strike your interest. \n\nAlternatively, you may already have a background in AI and if you are interested in getting more involved in AI ethics, consider registering in courses that help build systematic ways of AI ethics and fill potential gaps you have about AI knowledge. \n\nHere at UofT, there is PHL277 (‚ÄòData Ethics‚Äô) taught by Steven Coyne himself, which introduces the ethical problems posed by Big Data and algorithmic decision-making by considering concerns about AI ethics [7]. There are more courses in the Philosophy department that consider long-term, big pictures questions like human existentialism, as well as courses in the Computer Science department like CSC300 (‚ÄòComputers and Society‚Äô). \n\nThe best way to discover your particular interest or niche in AI, whether you are starting out or deepening your knowledge, is finding like-minded people who want to discuss AI ethics. Consider finding an extracurricular club of other students in similar positions who want to talk about these issues.\n\n\u003cstrong\u003eWhere Do We Go From Here?\u003c/strong\u003e\nThe lingering question remains, where do we go from here? The field of AI is evolving and the technology that rises from it is innovative and transformative but it is also uncharted territory which necessitates further discussion of its development, deployment, and use to ensure it is ethical. Steven is featured on the first of many videos from IlluminAI with different speakers and different topics, and more opportunities to join the conversation on AI ethics. Stay tuned. \n\n\u003ch1\u003eREFERENCES\u003c/h1\u003e\n\u003cstrong\u003e[1]\u003c/strong\u003e Eubanks, V. (2018). Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor. St. Martin‚Äôs Press.\n\u003ca href=\"https://tetrazolelover.at.ua/virginia_eubanks-automating_inequality-how_high-te.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://tetrazolelover.at.ua/virginia_eubanks-automating_inequality-how_high-te.pdf\u003c/a\u003e\n\u003cstrong\u003e[2]\u003c/strong\u003e D‚ÄôIgnazio, C., \u0026 Klein, L. F. (2024). Data Feminism for AI. ACM FAccT Conference.\n\u003ca href=\"https://facctconference.org/static/papers24/facct24-7.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://facctconference.org/static/papers24/facct24-7.pdf\u003c/a\u003e\n\u003cstrong\u003e[3]\u003c/strong\u003e Schrage, M., \u0026 Kiron, D. (2025). Philosophy Eats AI. MIT Sloan Management Review.\n\u003ca href=\"https://sloanreview.mit.edu/article/philosophy-eats-ai/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://sloanreview.mit.edu/article/philosophy-eats-ai/\u003c/a\u003e\n\u003cstrong\u003e[4]\u003c/strong\u003e View of Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval.\n\u003cstrong\u003e[5]\u003c/strong\u003e Using Artificial Intelligence on Dermatology Conditions in Uganda: A Case for Diversity in Training Data Sets for Machine Learning. bioRxiv.\n\u003cstrong\u003e[6]\u003c/strong\u003e Embedded Ethics Education Initiative (E3I), University of Toronto.\n\u003ca href=\"https://www.cs.toronto.edu/embedded-ethics/about.html\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.cs.toronto.edu/embedded-ethics/about.html\u003c/a\u003e\n\u003cstrong\u003e[7]\u003c/strong\u003e University of Toronto Faculty of Arts \u0026 Science. PHL277H1 ‚Äì Data Ethics.\n\u003ca href=\"https://artsci.calendar.utoronto.ca/course/phl277h1\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://artsci.calendar.utoronto.ca/course/phl277h1\u003c/a\u003e\n\u003cstrong\u003e[8]\u003c/strong\u003e University of Toronto. U of T CS Ethics Education Initiative Recognized with D2L Innovation Award.\n\u003ca href=\"https://web.cs.toronto.edu/news-events/news/u-of-t-cs-ethics-education-initiative-recognized-with-prestigious-d2l-innovation-award-in-teaching-and-learning\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://web.cs.toronto.edu/news-events/news/u-of-t-cs-ethics-education-initiative-recognized-with-prestigious-d2l-innovation-award-in-teaching-and-learning\u003c/a\u003e\n\u003cstrong\u003e[9]\u003c/strong\u003e ISO. Responsible AI and Ethics.\n\u003ca href=\"https://www.iso.org/artificial-intelligence/responsible-ai-ethics\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.iso.org/artificial-intelligence/responsible-ai-ethics\u003c/a\u003e\n\u003cstrong\u003e[10]\u003c/strong\u003e Schwartz Reisman Institute for Technology \u0026 Society (YouTube).\n\u003ca href=\"https://www.youtube.com/c/SchwartzReismanInstitute\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.youtube.com/c/SchwartzReismanInstitute\u003c/a\u003e\n\u003cstrong\u003e[11]\u003c/strong\u003e CBS News. Doctored Nancy Pelosi Video Highlights Threat of Deepfake Tech (2019).\n\u003ca href=\"https://www.cbsnews.com/news/doctored-nancy-pelosi-video-highlights-threat-of-deepfake-tech-2019-05-25/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.cbsnews.com/news/doctored-nancy-pelosi-video-highlights-threat-of-deepfake-tech-2019-05-25/\u003c/a\u003e\n\u003cstrong\u003e[12]\u003c/strong\u003e Euronews. Does Facebook‚Äôs New Policy on Deepfake Videos Go Far Enough? (2020).\n\u003ca href=\"https://www.euronews.com/my-europe/2020/01/07/does-facebook-s-new-policy-on-deepfake-videos-go-far-enough-thecube\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.euronews.com/my-europe/2020/01/07/does-facebook-s-new-policy-on-deepfake-videos-go-far-enough-thecube\u003c/a\u003e\n\u003cstrong\u003e[13]\u003c/strong\u003e Hockey Patrol. Fans React After Maple Leafs Use AI in 2025‚Äì26 Season Hype Video.\n\u003ca href=\"https://www.hockeypatrol.com/nhl-team/toronto-maple-leafs/fans-react-after-maple-leafs-use-ai-in-2025-26-season-hype-video\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.hockeypatrol.com/nhl-team/toronto-maple-leafs/fans-react-after-maple-leafs-use-ai-in-2025-26-season-hype-video\u003c/a\u003e\n\u003cstrong\u003e[14]\u003c/strong\u003e Toronto Star. These Ads Near Union Station Could Be Recording You.\n\u003ca href=\"https://www.thestar.com/news/gta/these-ads-near-union-station-and-other-places-around-toronto-could-be-recording-you-what/article_7af7c920-1ce7-4b19-98db-4c22d742f202.html\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.thestar.com/news/gta/these-ads-near-union-station-and-other-places-around-toronto-could-be-recording-you-what/article_7af7c920-1ce7-4b19-98db-4c22d742f202.html\u003c/a\u003e\n\u003cstrong\u003e[15]\u003c/strong\u003e IBM Think. Examining Superintelligence.\n\u003ca href=\"https://www.ibm.com/think/insights/examining-superintelligence\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://www.ibm.com/think/insights/examining-superintelligence\u003c/a\u003e\n\u003cstrong\u003e[16]\u003c/strong\u003e Towards Data Science. Stop Worrying About AGI ‚Äî The Immediate Danger Is Reduced General Intelligence.\n\u003ca href=\"https://towardsdatascience.com/stop-worrying-about-agi-the-immediate-danger-is-reduced-general-intelligence-rgi/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://towardsdatascience.com/stop-worrying-about-agi-the-immediate-danger-is-reduced-general-intelligence-rgi/\u003c/a\u003e\n\u003cstrong\u003e[17]\u003c/strong\u003e Stanford HAI. Privacy in an AI Era: How Do We Protect Our Personal Information?\n\u003cstrong\u003e[18]\u003c/strong\u003e Harvard Division of Continuing Education. Ethics in AI: Why It Matters.\n\u003ca href=\"https://professional.dce.harvard.edu/blog/ethics-in-ai-why-it-matters/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehttps://professional.dce.harvard.edu/blog/ethics-in-ai-why-it-matters/\u003c/a\u003e\n\u003cstrong\u003e[19]\u003c/strong\u003e Why Is Interdisciplinary Collaboration Essential for AI Ethics?"])</script><script>self.__next_f.push([1,"1a:T86f,"])</script><script>self.__next_f.push([1,"Hi Lumens,\n\nWelcome to the new blog initiative at IlluminAI. Our mission starts from a single belief: artificial intelligence (AI) is about people and is for everyone. \n\nAs advances in AI accelerate and become woven into our daily lives, we believe it‚Äôs crucial to amplify diverse perspectives and bring together many voices to shape the future we‚Äôll be living in together. This blog is one of the ways we‚Äôll do that: a place to share ideas, questions, concerns, and creativity around AI.\n\nIt‚Äôs easy to think of AI as something abstract or \"too technical\", something that belongs only to engineers, labs, or tech companies. In universities and even in society more broadly, disciplines often become isolated from one another, especially when it comes to technology. But AI doesn‚Äôt exist on its own. It intersects with ethics, law, medicine, education, art, and our everyday choices. We recognize this separation can make people alienated, overwhelmed or even scared by the idea of ‚Äúartificial‚Äù intelligence. That‚Äôs why we want to bridge this gap and normalize interdisciplinary conversations about AI.\n\nWe believe every voice brings something insightful. Whether you see yourself as a writer, thinker, designer, engineer, researcher, or even just someone curious, you have something valuable to contribute here. With creativity and critical thinking at the core of our work, we welcome any skill, talent or perspective.\n\n This year, we‚Äôre excited to grow our work through video interviews with experts in the field, a growing collection of articles from our writers, magazines that centralizes the articles and graphic designs, and our flagship AI Ethics Conference, reimagined and expanded from our original hackathon format.\n\nAcross all of these initiatives, our goal is the same: to invite more people into the conversation about AI, to raise important questions, and to learn and grow together.\n\n Our doors are always open. If you‚Äôd like to join, contribute, or simply learn more, we‚Äôd love to have you with us. No experience is too little, and no interest is too small. \n\nWelcome to our community!\n\nCheers,\n\nilluminAI executive team"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"$L15\",null,{}],[\"$\",\"$L16\",null,{}],[\"$\",\"$L17\",null,{\"blog\":{\"slug\":\"intro-to-ai-ethics\",\"title\":\"A Brief Introduction to AI Ethics\",\"author\":\"Kassidy McDonald and Shirley Zhang\",\"image_credit\":\"Photo by Danny Choi\",\"date\":\"January 27, 2026\",\"excerpt\":\"From bias and privacy to deepfakes and superintelligence, AI ethics is no longer a niche concern. This piece breaks down why ethical AI matters, how it affects everyday life, and why shaping its future requires voices beyond tech alone.\",\"content\":\"$18\",\"image\":\"/images/blogs/intro-to-ai-ethics.png\"},\"relatedBlogs\":[{\"slug\":\"intro-to-ai-ethics\",\"title\":\"A Brief Introduction to AI Ethics\",\"author\":\"Kassidy McDonald and Shirley Zhang\",\"image_credit\":\"Photo by Danny Choi\",\"date\":\"January 27, 2026\",\"excerpt\":\"From bias and privacy to deepfakes and superintelligence, AI ethics is no longer a niche concern. This piece breaks down why ethical AI matters, how it affects everyday life, and why shaping its future requires voices beyond tech alone.\",\"content\":\"$19\",\"image\":\"/images/blogs/intro-to-ai-ethics.png\"},{\"slug\":\"letter-from-illuminai\",\"title\":\"üíå Letter From illuminAI\",\"author\":\"illuminAI Executive Team\",\"image_credit\":\"Photo by Danny Choi\",\"date\":\"November 21, 2025\",\"excerpt\":\"A brief introduction to illuminAI, on why we believe AI is about people, not just tech, and how our initiatives invite everyone to join the conversation on AI ethics.\",\"content\":\"$1a\",\"image\":\"/images/blogs/letter-from-illuminai.png\"}]}]]\n"])</script><script>self.__next_f.push([1,"13:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n11:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"illuminaite academy\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Demystifying the world of CS \u0026 AI. Building a network of interdisciplinary students \u0026 opportunities.\"}],[\"$\",\"meta\",\"3\",{\"name\":\"author\",\"content\":\"illuminaite academy\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"AI,computer science,education,technology,interdisciplinary,workshops,community\"}],[\"$\",\"meta\",\"5\",{\"name\":\"creator\",\"content\":\"illuminaite academy\"}],[\"$\",\"meta\",\"6\",{\"name\":\"publisher\",\"content\":\"illuminaite academy\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:title\",\"content\":\"illuminaite academy\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:description\",\"content\":\"Demystifying the world of CS \u0026 AI. Building a network of interdisciplinary students \u0026 opportunities.\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:url\",\"content\":\"https://illuminaite.github.io/\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:site_name\",\"content\":\"illuminaite academy\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"illuminaite academy\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"Demystifying the world of CS \u0026 AI. Building a network of interdisciplinary students \u0026 opportunities.\"}],[\"$\",\"link\",\"16\",{\"rel\":\"shortcut icon\",\"href\":\"/images/illuminaite_logo.ico\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/images/illuminaite_logo.ico\"}]]\n"])</script><script>self.__next_f.push([1,"f:null\n"])</script></body></html>